import com.qualcomm.hardware.limelightvision.LLResult;
import com.qualcomm.hardware.limelightvision.LLResultTypes;
import com.qualcomm.hardware.limelightvision.LLStatus;
import com.qualcomm.hardware.limelightvision.Limelight3A;

Limelight3A limelight;

@Override
public void init() {
    limelight = hardwareMap.get(Limelight3A.class, "limelight");
    limelight.setPollRateHz(100); // This sets how often we ask Limelight for data (100 times per second)
    limelight.start(); // This tells Limelight to start looking!
}
// First, tell Limelight your robot's current orientation
double robotYaw = m_gyro.getYaw();  
LimelightHelpers.SetRobotOrientation("", robotYaw, 0.0, 0.0, 0.0, 0.0, 0.0);
int[] validIDs = {3,4};
LimelightHelpers.SetFiducialIDFiltersOverride("limelight", validIDs);
"imumode_set" / SetIMUMode() // don't tounch//
LimelightHelpers.SetRobotOrientation("limelight", m_poseEstimator.getEstimatedPosition().getRotation().getDegrees(), 0, 0, 0, 0, 0);
LimelightHelpers.PoseEstimate mt2 = LimelightHelpers.getBotPoseEstimate_wpiBlue_MegaTag2("limelight");
if(Math.abs(m_gyro.getRate()) > 720) // if our angular velocity is greater than 720 degrees per second, ignore vision updates
{
  doRejectUpdate = true;
}
if(mt2.tagCount == 0)
{
  doRejectUpdate = true;
}
if(!doRejectUpdate)
{
  m_poseEstimator.setVisionMeasurementStdDevs(VecBuilder.fill(.7,.7,9999999));
  m_poseEstimator.addVisionMeasurement(
      mt2.pose,
      mt2.timestampSeconds);
}

//dont use code below// //
limelight.pipelineSwitch(0); // Switch to pipeline number 0
LLResult result = limelight.getLatestResult();
if (result != null && result.isValid()) {
    double tx = result.getTx(); // How far left or right the target is (degrees)
    double ty = result.getTy(); // How far up or down the target is (degrees)
    double ta = result.getTa(); // How big the target looks (0%-100% of the image)
    
    telemetry.addData("Target X", tx);
    telemetry.addData("Target Y", ty);
    telemetry.addData("Target Area", ta);
} else {
    telemetry.addData("Limelight", "No Targets");
}
if (result != null && result.isValid()) {
    Pose3D botpose = result.getBotpose();
    if (botpose != null) {
        double x = botpose.getPosition().x;
        double y = botpose.getPosition().y;
        telemetry.addData("MT1 Location", "(" + x + ", " + y + ")");
    }
}
// First, tell Limelight which way your robot is facing
double robotYaw = imu.getAngularOrientation().firstAngle;
limelight.updateRobotOrientation(robotYaw);
if (result != null && result.isValid()) {
    Pose3D botpose_mt2 = result.getBotpose_MT2();
    if (botpose_mt2 != null) {
        double x = botpose_mt2.getPosition().x;
        double y = botpose_mt2.getPosition().y;
        telemetry.addData("MT2 Location:", "(" + x + ", " + y + ")");
    }
}
List<ColorResult> colorTargets = result.getColorResults();
for (ColorResult colorTarget : colorTargets) {
    double x = detection.getTargetXDegrees(); // Where it is (left-right)
    double y = detection.getTargetYDegrees(); // Where it is (up-down)
    double area = colorTarget.getTargetArea(); // size (0-100)
    telemetry.addData("Color Target", "takes up " + area + "% of the image");
}
List<FiducialResult> fiducials = result.getFiducialResults();
for (FiducialResult fiducial : fiducials) {
    int id = fiducial.getFiducialId(); // The ID number of the fiducial
    double x = detection.getTargetXDegrees(); // Where it is (left-right)
    double y = detection.getTargetYDegrees(); // Where it is (up-down)
    double StrafeDistance_3D = fiducial.getRobotPoseTargetSpace().getY(); 
    telemetry.addData("Fiducial " + id, "is " + distance + " meters away");
}
fiducial.getRobotPoseTargetSpace(); // Robot pose relative it the AprilTag Coordinate System (Most Useful)
fiducial.getCameraPoseTargetSpace(); // Camera pose relative to the AprilTag (useful)
fiducial.getRobotPoseFieldSpace(); // Robot pose in the field coordinate system based on this tag alone (useful)
fiducial.getTargetPoseCameraSpace(); // AprilTag pose in the camera's coordinate system (not very useful)
fiducial.getTargetPoseRobotSpace(); // AprilTag pose in the robot's coordinate system (not very useful)
List<BarcodeResult> barcodes = result.getBarcodeResults();
for (BarcodeResult barcode : barcodes) {
    String data = barcode.getData(); // What the barcode says
    String family = barcode.getFamily(); // What type of barcode it is
    telemetry.addData("Barcode", data + " (" + family + ")");
}
List<ClassifierResult> classifications = result.getClassifierResults();
for (ClassifierResult classification : classifications) {
    String className = classification.getClassName(); // What Limelight thinks it sees
    double confidence = classification.getConfidence(); // Confidence Score
    telemetry.addData("I see a", className + " (" + confidence + "%)");
}
List<DetectorResult> detections = result.getDetectorResults();
for (DetectorResult detection : detections) {
    String className = detection.getClassName(); // What was detected
    double x = detection.getTargetXDegrees(); // Where it is (left-right)
    double y = detection.getTargetYDegrees(); // Where it is (up-down)
    telemetry.addData(className, "at (" + x + ", " + y + ") degrees");
}
long staleness = result.getStaleness();
if (staleness < 100) { // Less than 100 milliseconds old
    telemetry.addData("Data", "Good");
} else {
    telemetry.addData("Data", "Old (" + staleness + " ms)");
}
LLFieldMap fieldMap = new LLFieldMap(); // You'll need to fill this with field data
boolean success = limelight.uploadFieldmap(fieldMap, null); // null means use the default slot
if (success) {
    telemetry.addData("Field Map", "Uploaded successfully!");
} else {
    telemetry.addData("Field Map", "Oops, upload failed");
}
limelight.captureSnapshot("auto_pov_10s");
limelight.deleteSnapshots();
telemetry.addData("Snapshots", "All cleared out!");
// In your periodic function:
LimelightHelpers.PoseEstimate limelightMeasurement = LimelightHelpers.getBotPoseEstimate_wpiBlue("limelight");
if (limelightMeasurement.tagCount >= 2) {  // Only trust measurement if we see multiple tags
    m_poseEstimator.setVisionMeasurementStdDevs(VecBuilder.fill(0.7, 0.7, 9999999));
    m_poseEstimator.addVisionMeasurement(
        limelightMeasurement.pose,
        limelightMeasurement.timestampSeconds
    );
}


// Get the pose estimate
LimelightHelpers.PoseEstimate limelightMeasurement = LimelightHelpers.getBotPoseEstimate_wpiBlue("");

// Add it to your pose estimator
m_poseEstimator.setVisionMeasurementStdDevs(VecBuilder.fill(.5, .5, 9999999));
m_poseEstimator.addVisionMeasurement(
    limelightMeasurement.pose,
    limelightMeasurement.timestampSeconds
);
// Switch to pipeline 0
LimelightHelpers.setPipelineIndex("", 0);
// Basic targeting data
double tx = LimelightHelpers.getTX("");  // Horizontal offset from crosshair to target in degrees
double ty = LimelightHelpers.getTY("");  // Vertical offset from crosshair to target in degrees
double ta = LimelightHelpers.getTA("");  // Target area (0% to 100% of image)
boolean hasTarget = LimelightHelpers.getTV(""); // Do you have a valid target?

double txnc = LimelightHelpers.getTXNC("");  // Horizontal offset from principal pixel/point to target in degrees
double tync = LimelightHelpers.getTYNC("");  // Vertical  offset from principal pixel/point to target in degrees